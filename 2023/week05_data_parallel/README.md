# Week 5: Data-parallel training

* Lecture: [slides](./lecture5.pdf), [video](https://disk.yandex.ru/i/14QJM4oYzsBCRQ)
* Seminar: [link](./practice.ipynb), [video](https://disk.yandex.ru/i/qgk59FKHVABhKQ)
* Homework: see the [homework](./homework) folder

## Further reading
* [Python multiprocessing docs](https://docs.python.org/3/library/multiprocessing.html) (pay attention to `fork` vs `spawn`!)
* [PyTorch Distributed tutorial](https://pytorch.org/tutorials/intermediate/dist_tuto.html)
* [Collective communication protocols in NCCL](https://images.nvidia.com/events/sc15/pdfs/NCCL-Woolley.pdf)
* There's a ton of links on the slides, please check the PDF.
